{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5122182a",
   "metadata": {},
   "source": [
    "In this example we are going to scrape the [OpenSyllabus works page](https://analytics.opensyllabus.org/record/works) for books included on college syllabi.\n",
    "\n",
    "Traditionally Python programmers use [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) to scrape content from the interent. Instead of being *traditional*, we're going to use [Playwright](https://playwright.dev/python/), a **browser automation tool**! This means you actually control the browser! Filling out forms, clicking buttons, downloading documents... it's magic!!!✨✨✨\n",
    "\n",
    "# OpenSyllabus works list\n",
    "\n",
    "## What we'll learn/use\n",
    "\n",
    "- Selectors\n",
    "- 'Show more' button pagination\n",
    "- Creating and saving a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff9c1d",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We need to install a few tools first! Remove the `#` and run the cell to install the Python packages and browsers that we'll need for our scraping adventure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet lxml html5lib beautifulsoup4 pandas\n",
    "# %pip install --quiet playwright\n",
    "# !playwright install chrome firefox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368a4f9-4d78-4b0f-8f2d-2de96fbc7dcc",
   "metadata": {},
   "source": [
    "## Requests + BS4 = doesn't work\n",
    "\n",
    "First, let's see how we can tell that this site does *not* work with the \"normal\" approach to scraping, with requests and BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ec355-5882-4ff6-8b7e-64f85fc51ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://analytics.opensyllabus.org/record/works\")\n",
    "doc = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dacd72-3f24-4825-af92-dfcb698e416a",
   "metadata": {},
   "source": [
    "No errors yet, but let's try to find some book titles... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720064a1-0cc0-437c-9423-2d150d236dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.find_all(class_='sc-9d100f21-9 bNgiIK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781416d-e5b3-4861-b72d-46118a24dd75",
   "metadata": {},
   "source": [
    "No luck! Maybe if we look at the actual text of the response itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3c62d-7a77-4ce0-8b06-12a081fac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f1220-64d2-4dc4-8573-4aca7443b865",
   "metadata": {},
   "source": [
    "Looks like **the content isn't even on the page**. Now we can move on to *Playwright!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57a69e",
   "metadata": {},
   "source": [
    "## Opening up the browser and visiting our destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# \"Hey, open up a browser\"\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "\n",
    "# Create a new browser window\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.goto(\"https://analytics.opensyllabus.org/record/works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f4b9b",
   "metadata": {},
   "source": [
    "## Clicking load more buttons\n",
    "\n",
    "The page that we're looking at has plenty of data, but there's more in hiding – if you scroll to the bottom of the page you'll see a \"Show more\" button.\n",
    "\n",
    "Let's grab it using `page.get_by_text` and click it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97148402",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.get_by_text(\"Show more\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b637e",
   "metadata": {},
   "source": [
    "Again! and again! And again! Let's click it **five more times**.\n",
    "\n",
    "We'll wait one second between each click so it doesn't accidentally double-click the button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    await page.get_by_text(\"Show more\").click(timeout=5000)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b127ef22",
   "metadata": {},
   "source": [
    "If you replaced the `for i in range` with `while True` it would click forever and ever. Eventually the \"Show more\" button runs out and there's no more button on the page: Playwright will wait for \"Show more\" for 30 seconds before returning an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e4b00",
   "metadata": {},
   "source": [
    "## Grab the content from the page\n",
    "\n",
    "Now we need to get the *content* from the page. Everyone loves using BeautifulSoup to scrape, so why don't we just do that? You use `await page.content()` to save the contents of the page and feed it directly to BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = await page.content()\n",
    "doc = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94e6a2",
   "metadata": {},
   "source": [
    "Once you push the HTML from the Playwright page into BeautifulSoup, you can use all the same selectors and filters that you can in your \"normal\" scraping world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = doc.find_all(class_='sc-9d100f21-9 bNgiIK')\n",
    "for title in titles[:10]:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bbb7f",
   "metadata": {},
   "source": [
    "## Developing your selectors\n",
    "\n",
    "Let's be honest: **writing custom scraping code isn't anyone's favorite thing to do.**\n",
    "\n",
    "To put together your selectors to grab the \"right\" data, I suggest using [my ChatGPT prompt](https://chatgpt.com/share/683013d1-b394-800d-bbce-64a00778b0de) to help. You can see the [original prompt here](https://gist.github.com/jsoma/d46ba769764866331a83d702a3054751) if you'd like to use it with another AI tool.\n",
    "\n",
    "You want to right-click the data you're interested in, then select **Inspect**. That provides two approaches to finding your region of interest: either browsing around on the right-hand side...\n",
    "\n",
    "<img src=\"finding-row-1.gif\" style=\"max-width: 600px\">\n",
    "\n",
    "...or using the element selector and clicking on the left-hand side.\n",
    "\n",
    "<img src=\"finding-row-2.gif\" style=\"max-width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d8842",
   "metadata": {},
   "source": [
    "[Pandas](https://pandas.pydata.org/) is the Python equivalent to Excel, and it's great at dealing with tabular data! If you can build a list of dictionaries it's fantastic for saving the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c02ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for tr in doc.select(\"tr.duwfJU\"):\n",
    "    row = {}\n",
    "\n",
    "    try:\n",
    "        row[\"rank\"] = tr.select_one(\"p.hOuBOS\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        row[\"title\"] = tr.select_one(\"a[href^='/singleton/works'] p\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        row[\"author\"] = tr.select_one(\"a[href^='/singleton/authors'] p\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        row[\"score\"] = tr.select_one(\"div[name='score-star'] + p\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        row[\"appearances\"] = tr.select_one(\"div.elzFcv\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01960b02-29ab-4762-8afb-d7a30da741d6",
   "metadata": {},
   "source": [
    "## Saving the file\n",
    "\n",
    "Now we can save our pandas dataframe to a CSV to open up in Excel or wherever else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"books.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
